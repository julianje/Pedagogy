output<-data.frame(do.call(rbind,lapply(seq(1,20),function(x){return(GetLikelihood(x,proposedsourceA,proposedsourceB,Alpha))}))) %>%
add_rownames() %>% mutate(Source=paste(proposedsourceA,proposedsourceB,Alpha))
names(output)=c("Item","Probability","Source")
return(output)
}
# Test combinations of the average and ideal
Mixtures_NormalTarget<-do.call(rbind,lapply(seq(0,1,0.1),function(x){return(TestSource("average","ideal",x))})) %>%
tbl_df %>% tidyr::separate(Source,into=c("Trash","Mixture"),sep=-3) %>% select(-Trash)
Mixtures_NormalTarget$Mixture<-as.numeric(Mixtures$Mixture)
Mixtures_NormalTarget$Item<-as.numeric(Mixtures$Item)
Mixtures_NormalTarget %>% ggplot(aes(x=Mixture,y=log(Probability),group=Item))+
geom_point()+geom_line()+facet_wrap(~Item,scales="free_y")+theme_linedraw()+
ggtitle("Probability of generating the normal distribution as a mixture of average and ideal")+scale_y_continuous("Log likelihood")
GetLikelihood<-function(QuestionId,SourceA,SourceB,Alpha){
Observations<-data %>% filter(Question==QuestionId,Type=="sample") %>%
select(Question,Value) %>% table %>% data.frame
# Make values numeric again
Observations$Value<-as.numeric(as.character(Observations$Value))
prod(do.call(rbind,lapply(seq(1,nrow(Observations)),function(x){
p1 <- GetSimpleLikelihood(Observations[x,]$Value,filter(EmpiricalDistributions,Question==QuestionId,Type==SourceA))
p2 <- GetSimpleLikelihood(Observations[x,]$Value,filter(EmpiricalDistributions,Question==QuestionId,Type==SourceB))
lp <- (Alpha*p1+(1-Alpha)*p2)^Observations[x,]$Freq
return(lp)
}))[,1])
}
# Test combinations of the average and ideal
Mixtures_SampleTarget<-do.call(rbind,lapply(seq(0,1,0.1),function(x){return(TestSource("average","ideal",x))})) %>%
tbl_df %>% tidyr::separate(Source,into=c("Trash","Mixture"),sep=-3) %>% select(-Trash)
Mixtures_SampleTarget$Mixture<-as.numeric(Mixtures$Mixture)
Mixtures_SampleTarget$Item<-as.numeric(Mixtures$Item)
Mixtures_SampleTarget %>% ggplot(aes(x=Mixture,y=log(Probability),group=Item))+
geom_point()+geom_line()+facet_wrap(~Item,scales="free_y")+theme_linedraw()+
ggtitle("Probability of generating the sample distribution as a mixture of average and ideal")+scale_y_continuous("Log likelihood")
# Test combinations of the average and ideal
Mixtures_SampleTarget<-do.call(rbind,lapply(seq(0,1,0.1),function(x){return(TestSource("average","ideal",x))})) %>%
tbl_df %>% tidyr::separate(Source,into=c("Trash","Mixture"),sep=-3) %>% select(-Trash)
Mixtures_SampleTarget$Mixture<-as.numeric(Mixtures$Mixture)
Mixtures_SampleTarget$Item<-as.numeric(Mixtures$Item)
Mixtures_SampleTarget %>% ggplot(aes(x=Mixture,y=log(Probability),group=Item))+
geom_point()+geom_line()+facet_wrap(~Item,scales="free_y")+theme_linedraw()+
ggtitle("Probability of generating the sample distribution as a mixture of average and ideal")+scale_y_continuous("Log likelihood")
Mixtures_SampleTarget %>% ggplot(aes(x=Mixture,y=log(Probability),group=Item))+
geom_point()+geom_line()+facet_wrap(~Item,scales="free_y")+theme_linedraw()+
ggtitle("Probability of generating the sample distribution as a mixture of average and ideal")+scale_y_continuous("Log likelihood")
MultipleSource_Sample<-Mixtures_SampleTarget %>% dplyr::group_by(Item) %>%
filter(Probability==max(Probability)) %>% arrange(Item) %>% mutate(Target="Sample")
MultipleSource_Normal<-Mixtures_NormalTarget %>% dplyr::group_by(Item) %>%
filter(Probability==max(Probability)) %>% arrange(Item) %>% mutate(Target="Normal")
rbind(MultipleSource_Sample, MultipleSource_Normal) %>% select(-Probability) %>%
spread(Target,Mixture) %>% ggplot(aes(x=Normal,y=Sample,label=Item))+geom_text()+theme_linedraw()+
scale_x_continuous("Mixture parameter\nfor generating normal")+scale_y_continuous("Mixture parameter\nfor generating samples")
setwd("~/Documents/Projects/Yale/Normality/")
data <- read.csv("SimplifiedData.csv") %>% tbl_df %>% gather(Variable,Value) %>%
filter(Value!="NA",Value!="",Value!=" ") %>%
tidyr::separate(Variable,into=c("Type","Question"),sep="_")
# Some values have commas. Get rid of them and make value column numeric.
data[which(data$Value=="1,000"),]$Value="1000"
data[which(data$Value=="2,000"),]$Value="2000"
data[which(data$Value=="3,000"),]$Value="3000"
data[which(data$Value=="5,000"),]$Value="5000"
data$Value=as.numeric(data$Value)
GetDistribution<-function(x,typeselection){data %>% filter(Question==x,Type==typeselection) %>%
select(Question,Value) %>% table %>% prop.table %>% data.frame %>%
dplyr::rename(Probability=Freq) %>% mutate(Type=typeselection) %>% return}
GetDistributionFrom<-function(ItemId){
do.call(rbind,lapply(names(table(data$Type)),function(x){return(GetDistribution(ItemId,x))}))
}
EmpiricalDistributions <- do.call(rbind,lapply(seq(1,20),GetDistributionFrom)) %>% tbl_df
EmpiricalDistributions$Value<-as.numeric(as.character(EmpiricalDistributions$Value))
GetSimpleLikelihood<-function(data,distribution){
prob<-filter(distribution,Value==data)$Probability
if (length(prob)==0){prob=0.01}
return(prob)
}
GetLikelihood<-function(QuestionId,Source,Target){
Observations<-data %>% filter(Question==QuestionId,Type==Target) %>%
select(Question,Value) %>% table %>% data.frame
# Make values numeric again
Observations$Value<-as.numeric(as.character(Observations$Value))
prod(do.call(rbind,lapply(seq(1,nrow(Observations)),function(x){
lp<-GetSimpleLikelihood(Observations[x,]$Value,filter(EmpiricalDistributions,Question==QuestionId,Type==Source))^Observations[x,]$Freq
return(lp)
}))[,1])
}
TestSource<-function(proposedsource,target){
output<-data.frame(do.call(rbind,lapply(seq(1,20),function(x){return(GetLikelihood(x,proposedsource,target))}))) %>%
add_rownames() %>% mutate(Source=proposedsource,Target=target)
names(output)=c("Item","Probability","Source","Target")
return(output)
}
Results<-do.call(rbind,
lapply(names(table(data$Type)),function(y){
return(do.call(rbind,
lapply(names(table(data$Type)),function(x){
return(TestSource(x,y))})))
})) %>% mutate(Same=(Source==Target)) %>% filter(Same==FALSE) %>% select(-Same)
Results$Item<-as.numeric(Results$Item)
Results
Results %>% ggplot(aes(x=Source,y=Target,fill=log(Probability)))+geom_tile()+
facet_wrap(~Item)+theme_linedraw()+
theme(axis.text.x = element_text(angle = -90, hjust = 1))
Results %>% group_by(Item) %>% filter(Probability == max(Probability)) %>% ungroup %>%
mutate(Relation=paste(Source, Target)) %>% select(Relation,-Item) %>% table %>% data.frame
Results %>% filter(Target=="normal") %>% group_by(Item) %>% filter(Probability == max(Probability)) %>% ungroup %>%
mutate(Relation=paste(Source, Target)) %>% select(Relation,-Item) %>% table %>% data.frame
SingeSourceProbabilities<-Results %>% filter(Target=="normal") %>% group_by(Item) %>% filter(Probability == max(Probability)) %>% ungroup %>%
mutate(Relation=paste(Source, Target)) %>% select(Relation,Probability,Item) %>% arrange(Item)
SingleSourceProbabilities<-Results %>% filter(Target=="normal") %>% group_by(Item) %>% filter(Probability == max(Probability)) %>% ungroup %>%
mutate(Relation=paste(Source, Target)) %>% select(Relation,Probability,Item) %>% arrange(Item)
GetLikelihood<-function(QuestionId,SourceA,SourceB,Alpha){
Observations<-data %>% filter(Question==QuestionId,Type=="normal") %>%
select(Question,Value) %>% table %>% data.frame
# Make values numeric again
Observations$Value<-as.numeric(as.character(Observations$Value))
prod(do.call(rbind,lapply(seq(1,nrow(Observations)),function(x){
p1 <- GetSimpleLikelihood(Observations[x,]$Value,filter(EmpiricalDistributions,Question==QuestionId,Type==SourceA))
p2 <- GetSimpleLikelihood(Observations[x,]$Value,filter(EmpiricalDistributions,Question==QuestionId,Type==SourceB))
lp <- (Alpha*p1+(1-Alpha)*p2)^Observations[x,]$Freq
return(lp)
}))[,1])
}
# Get the probability of generating each question's distribution for a given mixture of sources
TestSource<-function(proposedsourceA,proposedsourceB,Alpha){
output<-data.frame(do.call(rbind,lapply(seq(1,20),function(x){return(GetLikelihood(x,proposedsourceA,proposedsourceB,Alpha))}))) %>%
add_rownames() %>% mutate(Source=paste(proposedsourceA,proposedsourceB,Alpha))
names(output)=c("Item","Probability","Source")
return(output)
}
# Test combinations of the average and ideal
Mixtures_NormalTarget<-do.call(rbind,lapply(seq(0,1,0.1),function(x){return(TestSource("average","ideal",x))})) %>%
tbl_df %>% tidyr::separate(Source,into=c("Trash","Mixture"),sep=-3) %>% select(-Trash)
Mixtures_NormalTarget$Mixture<-as.numeric(Mixtures$Mixture)
Mixtures_NormalTarget$Mixture<-as.numeric(Mixtures_NormalTarget$Mixture)
Mixtures_NormalTarget$Item<-as.numeric(Mixtures_NormalTarget$Item)
Mixtures_NormalTarget %>% ggplot(aes(x=Mixture,y=log(Probability),group=Item))+
geom_point()+geom_line()+facet_wrap(~Item,scales="free_y")+theme_linedraw()+
ggtitle("Probability of generating the normal distribution as a mixture of average and ideal")+scale_y_continuous("Log likelihood")
Mixtures_NormalTarget %>% ggplot(aes(x=Mixture,y=log(Probability),group=Item))+
geom_point()+geom_line()+facet_wrap(~Item,scales="free_y")+theme_linedraw()+
ggtitle("Probability of generating the normal distribution as a\nmixture of average and ideal")+scale_y_continuous("Log likelihood")
GetLikelihood<-function(QuestionId,SourceA,SourceB,Alpha){
Observations<-data %>% filter(Question==QuestionId,Type=="sample") %>%
select(Question,Value) %>% table %>% data.frame
# Make values numeric again
Observations$Value<-as.numeric(as.character(Observations$Value))
prod(do.call(rbind,lapply(seq(1,nrow(Observations)),function(x){
p1 <- GetSimpleLikelihood(Observations[x,]$Value,filter(EmpiricalDistributions,Question==QuestionId,Type==SourceA))
p2 <- GetSimpleLikelihood(Observations[x,]$Value,filter(EmpiricalDistributions,Question==QuestionId,Type==SourceB))
lp <- (Alpha*p1+(1-Alpha)*p2)^Observations[x,]$Freq
return(lp)
}))[,1])
}
Mixtures_SampleTarget<-do.call(rbind,lapply(seq(0,1,0.1),function(x){return(TestSource("average","ideal",x))})) %>%
tbl_df %>% tidyr::separate(Source,into=c("Trash","Mixture"),sep=-3) %>% select(-Trash)
Mixtures_SampleTarget$Mixture<-as.numeric(Mixtures_SampleTarget$Mixture)
Mixtures_SampleTarget$Item<-as.numeric(Mixtures_SampleTarget$Item)
Mixtures_SampleTarget %>% ggplot(aes(x=Mixture,y=log(Probability),group=Item))+
geom_point()+geom_line()+facet_wrap(~Item,scales="free_y")+theme_linedraw()+
ggtitle("Probability of generating the sample distribution as a mixture of average and ideal")+scale_y_continuous("Log likelihood")
Mixtures_SampleTarget %>% ggplot(aes(x=Mixture,y=log(Probability),group=Item))+
geom_point()+geom_line()+facet_wrap(~Item,scales="free_y")+theme_linedraw()+
ggtitle("Probability of generating the sample distribution as a\nmixture of average and ideal")+scale_y_continuous("Log likelihood")
MultipleSource_Sample<-Mixtures_SampleTarget %>% dplyr::group_by(Item) %>%
filter(Probability==max(Probability)) %>% arrange(Item) %>% mutate(Target="Sample")
MultipleSource_Normal<-Mixtures_NormalTarget %>% dplyr::group_by(Item) %>%
filter(Probability==max(Probability)) %>% arrange(Item) %>% mutate(Target="Normal")
rbind(MultipleSource_Sample, MultipleSource_Normal) %>% select(-Probability) %>%
spread(Target,Mixture) %>% ggplot(aes(x=Normal,y=Sample,label=Item))+geom_text()+theme_linedraw()+
scale_x_continuous("Mixture parameter\nfor generating normal")+scale_y_continuous("Mixture parameter\nfor generating samples")
MultipleSource_Sample
MultipleSource_Normal
rbind(MultipleSource_Sample, MultipleSource_Normal)
rbind(MultipleSource_Sample, MultipleSource_Normal) %>% select(-Probability)
MultipleSource_Normal
MultipleSource_Sample<-Mixtures_SampleTarget %>% dplyr::group_by(Item) %>%
filter(Probability==max(Probability)) %>% arrange(Item) %>% mutate(Target="Sample") %>% ungroup()
MultipleSource_Normal<-Mixtures_NormalTarget %>% dplyr::group_by(Item) %>%
filter(Probability==max(Probability)) %>% arrange(Item) %>% mutate(Target="Normal") %>% ungroup()
rbind(MultipleSource_Sample, MultipleSource_Normal) %>% select(-Probability) %>%
spread(Target,Mixture) %>% ggplot(aes(x=Normal,y=Sample,label=Item))+geom_text()+theme_linedraw()+
scale_x_continuous("Mixture parameter\nfor generating normal")+scale_y_continuous("Mixture parameter\nfor generating samples")
MixParams<-rbind(MultipleSource_Sample, MultipleSource_Normal) %>% select(-Probability) %>%
spread(Target,Mixture) %>% select(Normal,Sample)
cor.test(MixParams$Normal,MixParams$Sample)
rbind(mutate(select(SingeSourceProbabilities,-Relation),Source="Single"),
mutate(select(MultipleSource_Normal,-Mixture,-Target),Source="Mixture")) %>%
ggplot(aes(x=Item,y=log(Probability),color=Source,group=Source))+geom_point()+theme_linedraw()+geom_line()
rbind(mutate(select(SingleSourceProbabilities,-Relation),Source="Single"),
mutate(select(MultipleSource_Normal,-Mixture,-Target),Source="Mixture")) %>%
ggplot(aes(x=Item,y=log(Probability),color=Source,group=Source))+geom_point()+theme_linedraw()+geom_line()
data %>% dplyr::group_by(Type,Question) %>%
dplyr::summarise(sd=sd(Value)) %>%
ggplot(aes(x=Question,y=sd,color=Type))+geom_point()+facet_wrap(~Question,scales="free")+
theme_linedraw()
data %>% filter(Type %in% c("normal","sample")) %>%
ggplot(aes(x=Value,fill=Type))+geom_density(alpha=3/4)+facet_wrap(~Question,scales="free")
data %>% filter(Type %in% c("normal","sample")) %>%
ggplot(aes(x=Value,fill=Type))+geom_histogram(alpha=3/4)+facet_wrap(Type~Question,scales="free")
data %>% filter(Type %in% c("average","ideal","normal")) %>%
ggplot(aes(x=Question,y=(Value),color=Type))+
geom_point(alpha=3/4,position=position_jitter(height=0,width=0.3))+
facet_wrap(~Question,scales="free")+theme_linedraw()
rm (list = ls(all = TRUE)) # Clean everything
options(warn=-1) # Boot.ci() keeps waning about needing variances for t-intervals. But we don't use those.
# Load packages
library(tidyr)
library(dplyr)
library(plyr)
library(ggplot2)
library(boot)
library(magrittr)
library(nlme)
# Set working directory
setwd("~/Documents/Projects/SamplingAndEfficiency/Big World/Experiment1/Experiment1Results/")
# Part 0: Get demographics ------------------
# Load ages
demographics <- read.csv("../Experiment1Results/Demographics.csv") %>% tbl_df %>%
select(Answer.Age,Answer.surveycode) %>%
dplyr::rename(Age=Answer.Age,SurveyCode=Answer.surveycode) %>%
tidyr::separate(SurveyCode,into=c("Trash","SubjectId"),sep=2) %>%
select(-Trash)
summary(demographics$Age)
rm(demographics)
# Part 1: Load data -----------------------------------------------------
# Load data and remove columms you don't need
models<-read.csv("../Model_Predictions/final_data.csv") %>% select(-WorldName,-NPickUp,-CanHold1AtATime) %>% tbl_df
# TrueValue column is stored as strings. Convert it to factors
models$TrueValue<-factor(models$TrueValue)
models<-select(models,-(p_val:Cost),-MAP)
levels(models$TrueValue)<-c("N","P") # Change the factor's levels
models$SD=-models$SD
# Z-score models
models <- plyr::ddply(models,c("Model"),function(x){
return(data.frame(Quantity = x$Quantity,
Location = x$Location,
TrueValue = x$TrueValue,
WorldType = x$WorldType,
InferredVal = scale(x$InferredVal)[,1],
SD = scale(x$SD)[,1],
VariedCollection = x$VariedCollection))
})
# Load experiment results
human<-read.csv("SAE.csv") %>% tbl_df
# Get preference judgments for object 1 (fix scale depending on stimuli type the participant saw)
human$Preference=(1-human$Preference)*(1-human$StimType)+(human$Preference)*(human$StimType)
# Z-score each participant's answers and remove SubjectId
human<-plyr::ddply(human,c("SubjectId","ExpCondition"),function(x){
return(data.frame(Preference=scale(x$Preference)[,1],
Confidence=scale(x$Confidence)[,1],
TrialName=x$TrialName))
}) %>% tbl_df
# TrialName column has the image file. Extract the stimuli condition from the string
human<-separate(human,TrialName,c("Trash","TrialName"),sep=4) %>% # split "img-" to a different column
select(-Trash) %>% # And delete that column
separate(TrialName,c("Quantity","Location"),sep=1) %>% # Take the first character and save into Quantity column
separate(Location,c("Location","Rest"),sep=1) %>% # Take second character and save into location column
separate(Rest,c("TrueValue","Trash"),sep=1) %>% select(-Trash) # Save last character and delete ".gif"
# Convert all characters into factors and add correct levels
human$Quantity<-factor(human$Quantity)
levels(human$Quantity)<-c("Even","Plentiful","Scarce")
human$Location<-factor(human$Location)
levels(human$Location)<-c("Closer","Farther","Random")
# Rename columns so we can merge them with model predictions
human<-dplyr::rename(human,HumanPref=Preference, HumanConf=Confidence, WorldType=ExpCondition)
RawData <- dplyr::full_join(human,models) %>% tbl_df
getCI<-function(inputdata){
samples<-boot(inputdata,function(x,id){return(mean(x[id,]$HumanPref))},10000)
ci<-boot.ci(samples,type="basic")
return(c(ci$basic[4],ci$basic[5]))
}
set.seed(2837495)
CIs<-plyr::ddply(human,c("Quantity","Location","TrueValue","WorldType"),getCI)
CIs %<>% dplyr::rename(Lower=V1,Upper=V2)
# Now get the average human judgment
human<-human %>% dplyr::group_by(Quantity,Location,TrueValue,WorldType) %>%
dplyr::summarise(HumanPref=mean(HumanPref),HumanConf=mean(HumanConf))
# Invert confidence judgments so 0 means extremely confident and 1 means not confident at all.
# human$HumanConf=human$HumanConf*(-1)
# Create new data frame with human and model results
AllData<-dplyr::full_join(human,models,by=c("Quantity","Location","TrueValue","WorldType")) %>% tbl_df
rm(human,models)
human<-read.csv("SAE.csv") %>% tbl_df
human$Preference=(1-human$Preference)*(1-human$StimType)+(human$Preference)*(human$StimType)
humansd<-human %>% dplyr::group_by(TrialName,ExpCondition) %>% dplyr::summarise(conf_human = sd(Preference))
humansd
tidyr::separate(humansd,TrialName,c("Trash","TrialName"),sep=4) %>% # split "img-" to a different column
select(-Trash)
tidyr::separate(humansd,TrialName,c("Trash","TrialName"),sep=4) %>% # split "img-" to a different column
select(-Trash) %>% # And delete that column
tidyr::separate(TrialName,c("Quantity","Location"),sep=1)
humansd
humansd<-human %>% dplyr::group_by(TrialName,ExpCondition) %>%
dplyr::summarise(conf_human = sd(Preference)) %>% ungroup()
tidyr::separate(humansd,TrialName,c("Trash","TrialName"),sep=4) %>% # split "img-" to a different column
select(-Trash) %>% # And delete that column
tidyr::separate(TrialName,c("Quantity","Location"),sep=1)
tidyr::separate(humansd,TrialName,c("Trash","TrialName"),sep=4) %>% # split "img-" to a different column
select(-Trash) %>% # And delete that column
tidyr::separate(TrialName,c("Quantity","Location"),sep=1) %>% # Take the first character and save into Quantity column
tidyr::separate(Location,c("Location","Rest"),sep=1)
tidyr::separate(humansd,TrialName,c("Trash","TrialName"),sep=4) %>% # split "img-" to a different column
select(-Trash) %>% # And delete that column
tidyr::separate(TrialName,c("Quantity","Location"),sep=1) %>% # Take the first character and save into Quantity column
tidyr::separate(Location,c("Location","Rest"),sep=1) %>% # Take second character and save into location column
tidyr::separate(Rest,c("TrueValue","Trash"),sep=1)
# TrialName column has the image file. Extract the stimuli condition from the string
humansd <- tidyr::separate(humansd,TrialName,c("Trash","TrialName"),sep=4) %>% # split "img-" to a different column
select(-Trash) %>% # And delete that column
tidyr::separate(TrialName,c("Quantity","Location"),sep=1) %>% # Take the first character and save into Quantity column
tidyr::separate(Location,c("Location","Rest"),sep=1) %>% # Take second character and save into location column
tidyr::separate(Rest,c("TrueValue","Trash"),sep=1) %>% select(-Trash) # Save last character and delete ".gif"
humansd
humansd$Quantity<-factor(humansd$Quantity)
levels(humansd$Quantity)<-c("Even","Plentiful","Scarce")
humansd$Location<-factor(humansd$Location)
levels(humansd$Location)<-c("Closer","Farther","Random")
humansd
humansd<-dplyr::rename(humansd,HumanPref=Preference, HumanConf=conf_human, WorldType=ExpCondition)
humansd<-dplyr::rename(humansd, HumanConf=conf_human, WorldType=ExpCondition)
humansd
ConfData <- dplyr::full_join(humansd,models) %>% tbl_df
# Load data and remove columms you don't need
models<-read.csv("../Model_Predictions/final_data.csv") %>% select(-WorldName,-NPickUp,-CanHold1AtATime) %>% tbl_df
# TrueValue column is stored as strings. Convert it to factors
models$TrueValue<-factor(models$TrueValue)
models<-select(models,-(p_val:Cost),-MAP)
levels(models$TrueValue)<-c("N","P") # Change the factor's levels
models$SD=-models$SD
# Z-score models
models <- plyr::ddply(models,c("Model"),function(x){
return(data.frame(Quantity = x$Quantity,
Location = x$Location,
TrueValue = x$TrueValue,
WorldType = x$WorldType,
InferredVal = scale(x$InferredVal)[,1],
SD = scale(x$SD)[,1],
VariedCollection = x$VariedCollection))
})
ConfData <- dplyr::full_join(humansd,models) %>% tbl_df
ConfData
ConfData %>% filter(Model!="Empirical") %>% ggplot(aes(x=HumanConf,y=SD))+geom_point()+
facet_wrap(~Model)+theme_linedraw()
ConfData
ConfData %>% filter(Model!="Empirical") %>% dplyr::group_by(Model) %>% dplyr::summarise(r=cor(SD,HumanConf))
ConfData %>% filter(Model!="Empirical") %>% dplyr::group_by(Model) %>%
dplyr::summarise(r=cor(SD,HumanConf)) %>%
arrange(r)
rm (list = ls(all = TRUE)) # Clean everything
options(warn=-1)
library(dplyr)
library(tidyr)
library(ggplot2)
# Load data --------------
setwd("~/Documents/Projects/Yale/Normality/")
data <- read.csv("SimplifiedData.csv") %>% tbl_df %>% gather(Variable,Value) %>%
filter(Value!="NA",Value!="",Value!=" ") %>%
tidyr::separate(Variable,into=c("Type","Question"),sep="_")
# Some values have commas. Get rid of them and make value column numeric.
data[which(data$Value=="1,000"),]$Value="1000"
data[which(data$Value=="2,000"),]$Value="2000"
data[which(data$Value=="3,000"),]$Value="3000"
data[which(data$Value=="5,000"),]$Value="5000"
data$Value=as.numeric(data$Value)
# Get pure empirical distributions ----------------
# Take an item number and a judgment type and build an empirical distribution out of it.
GetDistribution<-function(x,typeselection){data %>% filter(Question==x,Type==typeselection) %>%
select(Question,Value) %>% table %>% prop.table %>% data.frame %>%
dplyr::rename(Probability=Freq) %>% mutate(Type=typeselection) %>% return}
# Extract distribution of each question type given item number
GetDistributionFrom<-function(ItemId){
do.call(rbind,lapply(names(table(data$Type)),function(x){return(GetDistribution(ItemId,x))}))
}
# Run everything for the 20 items and pack them up
EmpiricalDistributions <- do.call(rbind,lapply(seq(1,20),GetDistributionFrom)) %>% tbl_df
# Values are now factors so fix that. Make them characters first, otherwise as.numeric messes things up.
EmpiricalDistributions$Value<-as.numeric(as.character(EmpiricalDistributions$Value))
# Now take the normal answers and compute the likelihood that they were generated from each source
# Take a datapoint and return its probability given an empirical distribution.
GetSimpleLikelihood<-function(data,distribution){
prob<-filter(distribution,Value==data)$Probability
if (length(prob)==0){prob=0.01}
return(prob)
}
# Get the likelihood that distributionA in a certain Question is generated by distributionB
GetLikelihood<-function(QuestionId,Source,Target){
Observations<-data %>% filter(Question==QuestionId,Type==Target) %>%
select(Question,Value) %>% table %>% data.frame
# Make values numeric again
Observations$Value<-as.numeric(as.character(Observations$Value))
prod(do.call(rbind,lapply(seq(1,nrow(Observations)),function(x){
lp<-GetSimpleLikelihood(Observations[x,]$Value,filter(EmpiricalDistributions,Question==QuestionId,Type==Source))^Observations[x,]$Freq
return(lp)
}))[,1])
}
# Get the probability of generating each question's distribution for a given source and target
TestSource<-function(proposedsource,target){
output<-data.frame(do.call(rbind,lapply(seq(1,20),function(x){return(GetLikelihood(x,proposedsource,target))}))) %>%
add_rownames() %>% mutate(Source=proposedsource,Target=target)
names(output)=c("Item","Probability","Source","Target")
return(output)
}
# Test all possible sources and targets
Results<-do.call(rbind,
lapply(names(table(data$Type)),function(y){
return(do.call(rbind,
lapply(names(table(data$Type)),function(x){
return(TestSource(x,y))})))
})) %>% mutate(Same=(Source==Target)) %>% filter(Same==FALSE) %>% select(-Same)
Results$Item<-as.numeric(Results$Item)
Results %>% ggplot(aes(x=Source,y=Target,fill=log(Probability)))+geom_tile()+
facet_wrap(~Item)+theme_linedraw()+
theme(axis.text.x = element_text(angle = -90, hjust = 1))
data
data %>% filter(Type %in% c("normal","sample"))
data %>% filter(Type %in% c("normal","sample"))
data %>% filter(Type %in% c("normal","sample")) %>% ggplot(aes(x=Value,fill=Type))+geom_density(alpha=3/4)+facet_wrap(~Question)
data %>% filter(Type %in% c("normal","sample")) %>% ggplot(aes(x=Value,fill=Type))+geom_density(alpha=3/4)+facet_wrap(~Question,scales="free")
library(plyr, quietly=T, warn.conflicts=F)
library(dplyr, quietly=T, warn.conflicts=F)
library(ggplot2, quietly=T, warn.conflicts=F)
library(ggvis, quietly=T, warn.conflicts=F)
library(tidyr, quietly=T, warn.conflicts=F)
library(knitr, quietly=T, warn.conflicts=F)
library(boot, quietly=T, warn.conflicts=F)
setwd("~/Documents/Projects/Models/Pedagogy/Pedagogy/Data/")
setwd("~/Documents/Projects/Models/Pedagogy/Pedagogy/Data/")
dataC <- read.csv("Data/ModelPredictions_TeacherReward.csv") %>% tbl_df %>% mutate(Model=paste(LearnC,LearnR,TeachC,TeachR,DiscoverC,DiscoverR))
library(plyr, quietly=T, warn.conflicts=F)
library(dplyr, quietly=T, warn.conflicts=F)
library(ggplot2, quietly=T, warn.conflicts=F)
library(ggvis, quietly=T, warn.conflicts=F)
library(tidyr, quietly=T, warn.conflicts=F)
library(knitr, quietly=T, warn.conflicts=F)
library(boot, quietly=T, warn.conflicts=F)
setwd("~/Documents/Projects/Models/Pedagogy/Pedagogy/Data/")
dataA <- read.csv("ModelPredictions_FullJoint.csv") %>% tbl_df %>% mutate(Model=paste(LearnC,LearnR,TeachC,TeachR,DiscoverC,DiscoverR))
dataB <- read.csv("ModelPredictions_UncertaintySearch.csv") %>% tbl_df %>% mutate(Model=paste(LearnC,LearnR,TeachC,TeachR,DiscoverC,DiscoverR))
dataC <- read.csv("ModelPredictions_TeacherReward.csv") %>% tbl_df %>% mutate(Model=paste(LearnC,LearnR,TeachC,TeachR,DiscoverC,DiscoverR))
data<-rbind(dataA,dataB,dataC)
levels(data$Condition)
levels(data$Condition)=c("1: Equal\nCosts","4: Inverted\nRewards","3: Matched\nRewards","2: Unequal\nCosts")
data$Condition<-as.character(data$Condition)
data$ExploreProb<-factor(data$ExploreProb)
levels(data$ExploreProb)
levels(data$ExploreProb)=c(".25 Exploration",".5 Exploration",".75 Exploration","Exploration\ncertainty")
levels(data$TeacherReward)
levels(data$TeacherReward)=c("Constant\nteacher reward","Variable\nteacher reward")
levels(data$Decision)
levels(data$Decision)=c("Either","Red toy","Yellow toy")
Summarydata<-plyr::ddply(data,c("ExploreProb","TeacherReward","Condition","Model"),function(x){return(data.frame(table(x$Decision)))}) %>% tbl_df %>% dplyr::rename(Decision=Var1)
Summarydata %>% filter(ExploreProb==".5 Exploration",
TeacherReward=="Constant\nteacher reward",
Condition=="1: Equal\nCosts",
Model=="0 0 0 0 1 1") %>% select(Freq) %>% sum
Total<-Summarydata %>% filter(ExploreProb==".5 Exploration",
TeacherReward=="Constant\nteacher reward",
Condition=="1: Equal\nCosts",
Model=="0 0 0 0 1 1") %>% select(Freq) %>% sum
Summarydata <- Summarydata %>% mutate(Percentage=Freq*100/Total) %>% select(-Freq)
Summarydata <- Summarydata %>% mutate(Percentage=Freq*100/Total) %>% select(-Freq)
Summarydata
ConcreteChoices <- Summarydata %>% filter(Decision %in% c("Yellow toy","Red toy"))
NoPref <- Summarydata %>% filter(Decision %in% c("Either")) %>% mutate(PercAdd=Percentage/2) %>% select(-Percentage,-Decision)
Simpledata <- full_join(ConcreteChoices,NoPref,by=c("ExploreProb","TeacherReward","Condition","Model")) %>% mutate(Perc=Percentage+PercAdd) %>% select(-Percentage,-PercAdd)
rm(ConcreteChoices,NoPref,data,dataA,dataB)
library(plyr, quietly=T, warn.conflicts=F)
library(dplyr, quietly=T, warn.conflicts=F)
library(ggplot2, quietly=T, warn.conflicts=F)
library(ggvis, quietly=T, warn.conflicts=F)
library(tidyr, quietly=T, warn.conflicts=F)
library(knitr, quietly=T, warn.conflicts=F)
library(boot, quietly=T, warn.conflicts=F)
setwd("~/Documents/Projects/Models/Pedagogy/Pedagogy/Data/")
dataA <- read.csv("ModelPredictions_FullJoint.csv") %>% tbl_df %>% mutate(Model=paste(LearnC,LearnR,TeachC,TeachR,DiscoverC,DiscoverR))
dataB <- read.csv("ModelPredictions_UncertaintySearch.csv") %>% tbl_df %>% mutate(Model=paste(LearnC,LearnR,TeachC,TeachR,DiscoverC,DiscoverR))
dataC <- read.csv("ModelPredictions_TeacherReward.csv") %>% tbl_df %>% mutate(Model=paste(LearnC,LearnR,TeachC,TeachR,DiscoverC,DiscoverR))
data<-rbind(dataA,dataB,dataC)
levels(data$Condition)=c("1: Equal\nCosts","4: Inverted\nRewards","3: Matched\nRewards","2: Unequal\nCosts")
data$Condition<-as.character(data$Condition)
data$ExploreProb<-factor(data$ExploreProb)
levels(data$ExploreProb)=c(".25 Exploration",".5 Exploration",".75 Exploration","Exploration\ncertainty")
levels(data$TeacherReward)=c("Constant\nteacher reward","Variable\nteacher reward")
levels(data$Decision)=c("Either","Red toy","Yellow toy")
data
plyr::ddply(data,c("ExploreProb","TeacherReward","Condition","Model"),function(x){return(data.frame(table(x$Decision)))}) %>% tbl_df %>% dplyr::rename(Decision=Var1)
Summarydata<-plyr::ddply(data,c("ExploreProb","TeacherReward","Condition","Model"),function(x){return(data.frame(table(x$Decision)))}) %>% tbl_df %>% dplyr::rename(Decision=Var1)
# Get total number of samples (for normalizing later) by subselecting one set
Total<-Summarydata %>% filter(ExploreProb==".5 Exploration",
TeacherReward=="Constant\nteacher reward",
Condition=="1: Equal\nCosts",
Model=="0 0 0 0 1 1") %>% select(Freq) %>% sum
Summarydata <- Summarydata %>% mutate(Percentage=Freq*100/Total) %>% select(-Freq)
Summarydata
Summarydata$Model
table(Summarydata$Model)
data.frame(table(Summarydata$Model))
ConcreteChoices <- Summarydata %>% filter(Decision %in% c("Yellow toy","Red toy"))
NoPref <- Summarydata %>% filter(Decision %in% c("Either")) %>% mutate(PercAdd=Percentage/2) %>% select(-Percentage,-Decision)
Simpledata <- full_join(ConcreteChoices,NoPref,by=c("ExploreProb","TeacherReward","Condition","Model")) %>% mutate(Perc=Percentage+PercAdd) %>% select(-Percentage,-PercAdd)
rm(ConcreteChoices,NoPref,data,dataA,dataB)
ModelSpace=c("1 1 0 0 1 1","1 0 0 0 1 0","0 1 0 0 0 1","1 1 0 0 0 0","0 0 0 0 1 1")
Tempdat<-Simpledata %>% filter(Model %in% ModelSpace)
Tempdat$Model<-factor(Tempdat$Model)
levels(Tempdat$Model)=c("Novel\nonly","Rewards\nonly","Costs\nonly","Learned\nonly","Full\nmodel")
Tempdat$Decision<-as.character(Tempdat$Decision)
Tempdat %>% ggplot(aes(x=Condition,y=Perc,fill=Decision))+geom_bar(stat="identity")+facet_grid(Model~ExploreProb)+theme_bw()+scale_fill_manual(values=c("#C7363D","#EBE549"))+scale_y_continuous("Percentage\nof choices")
ModelSpace=c("1 1 0 1 1 1","1 0 0 1 1 0","0 1 0 1 0 1","1 1 0 1 0 0","0 0 0 1 1 1")
Tempdat<-Simpledata %>% filter(Model %in% ModelSpace)
Tempdat$Model<-factor(Tempdat$Model)
levels(Tempdat$Model)=c("Novel\nonly","Rewards\nonly","Costs\nonly","Learned\nonly","Full\nmodel")
Tempdat$Decision<-as.character(Tempdat$Decision)
Tempdat %>% ggplot(aes(x=Condition,y=Perc,fill=Decision))+geom_bar(stat="identity")+facet_grid(Model~ExploreProb)+theme_bw()+scale_fill_manual(values=c("#C7363D","#EBE549"))+scale_y_continuous("Percentage\nof choices")
